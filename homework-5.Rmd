---
title: "Homework 5"
author: "PSTAT 131/231"
date: '2022-11-19'
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Elastic Net Tuning

For this assignment, we will be working with the file `"pokemon.csv"`, found in `/data`. The file is from Kaggle: <https://www.kaggle.com/abcsds/pokemon>.

The [Pokémon](https://www.pokemon.com/us/) franchise encompasses video games, TV shows, movies, books, and a card game. This data set was drawn from the video game series and contains statistics about 721 Pokémon, or "pocket monsters." In Pokémon games, the user plays as a trainer who collects, trades, and battles Pokémon to (a) collect all the Pokémon and (b) become the champion Pokémon trainer.

Each Pokémon has a [primary type](https://bulbapedia.bulbagarden.net/wiki/Type) (some even have secondary types). Based on their type, a Pokémon is strong against some types, and vulnerable to others. (Think rock, paper, scissors.) A Fire-type Pokémon, for example, is vulnerable to Water-type Pokémon, but strong against Grass-type.

![Fig 1. Vulpix, a Fire-type fox Pokémon from Generation 1.](images/vulpix.png){width="196"}

The goal of this assignment is to build a statistical learning model that can predict the **primary type** of a Pokémon based on its generation, legendary status, and six battle statistics.

Read in the file and familiarize yourself with the variables using `pokemon_codebook.txt`.


First, we need to load the libraries needed for the homework:

```{r}
library(tidyverse)
library(tidymodels)
library(janitor)
```

### Exercise 1

Install and load the `janitor` package. Use its `clean_names()` function on the Pokémon data, and save the results to work with for the rest of the assignment. What happened to the data? Why do you think `clean_names()` is useful?

**Answer**

```{r}
pokemon <- read_csv("data/Pokemon.csv") %>% 
  clean_names()
```

The names of the variables are now in lowercase and do not contain any space in between. Instead, they have an underscore to separate them. `clean_names()` allows us to transform the variable names and produce a consistent way of doing it. According to the help, it does it in snake case which is defined as lowercase and underscores instead of spaces. I think this homework is a good example of how useful this can be because we have a relatively small data set in terms of variables (only 13 variables) and it helped us clean the names and produce names that are consistent. This implies that in bigger data sets that con potentially contain more variables it would be very useful to produce this consistent names and deal correctly with spaces, symbols and names written in capital case.


### Exercise 2

Using the entire data set, create a bar chart of the outcome variable, `type_1`.

How many classes of the outcome are there? Are there any Pokémon types with very few Pokémon? If so, which ones?

For this assignment, we'll handle the rarer classes by simply filtering them out. Filter the entire data set to contain only Pokémon whose `type_1` is Bug, Fire, Grass, Normal, Water, or Psychic.

After filtering, convert `type_1` and `legendary` to factors.

**Answer**

Following Lab 5:
```{r}
# Bar Chart using the entire data set
bar_type1 = ggplot(pokemon) + geom_bar(aes(x = type_1), colour = 'navyblue', fill = 'light blue') + labs(title = "Pokemons by first type", y = 'Number of Pokemon', x = 'First type')
bar_type1

# Filter out the rare classes
pokemon_filtered <- pokemon %>% 
  filter(type_1 %in% c('Bug', 'Fire', 'Grass', 'Normal', 'Water', 'Psychic'))

# Convert `type_1` and `legendary` to factors
pokemon_filtered <- pokemon_filtered %>% 
  mutate(type_1 = factor(type_1), legendary = factor(legendary))
```

There are 18 classes of the outcome which means that there are 18 different first types for the Pokemon in the data. There are two of them that stand up because there are considerably less Pokemon in those two types which are Flying, follow by Fairy.


### Exercise 3

Perform an initial split of the data. Stratify by the outcome variable. You can choose a proportion to use. Verify that your training and test sets have the desired number of observations.

Next, use *v*-fold cross-validation on the training set. Use 5 folds. Stratify the folds by `type_1` as well. *Hint: Look for a `strata` argument.* Why might stratifying the folds be useful?

**Answer**

Following Lab 5:

```{r}
# Initial split
set.seed(3435)
pokemon_split <- initial_split(pokemon_filtered, prop = 0.70,
                               strata = type_1)
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)

dim(pokemon_train)
dim(pokemon_test)

# Use *v*-fold cross-validation on the training set with 5 folds
pokemon_folds <- vfold_cv(pokemon_train, strata = type_1, v = 5)
pokemon_folds
```

As usual I decided to use 0.7 for my proportion as I want to include more observations in the training set than in the testing set. The full filtered data set includes 458 observations adn 318 is approximately 70% of it which means that the training set has the expected amount of observations. Therefore, the testing set also has the correct number of pokemon.


### Exercise 4

Set up a recipe to predict `type_1` with `legendary`, `generation`, `sp_atk`, `attack`, `speed`, `defense`, `hp`, and `sp_def`.

- Dummy-code `legendary` and `generation`;

- Center and scale all predictors.

**Answer**

Following Lab 5:

```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + 
                           hp + sp_def, data = pokemon_train) %>% # Model with the predictors required
  step_dummy(all_nominal_predictors()) %>% # Dummy encode `legendary` and `generation` (only categorical)
  step_normalize(all_predictors()) # Center and scale all predictors
```


### Exercise 5

We'll be fitting and tuning an elastic net, tuning `penalty` and `mixture` (use `multinom_reg` with the `glmnet` engine).

Set up this model and workflow. Create a regular grid for `penalty` and `mixture` with 10 levels each; `mixture` should range from 0 to 1. For this assignment, we'll let `penalty` range from -5 to 5 (it's log-scaled).

How many total models will you be fitting when you fit these models to your folded data?

**Answer**

Following Lab 5:

```{r}
# Specify model:
elastic_net <- multinom_reg(penalty = tune(), mixture = tune()) %>% # Tune `penalty` and `mixture`
  set_mode("classification") %>% 
  set_engine("glmnet") # Use `multinom_reg` with the `glmnet` engine

# Create a workflow for the model
elastic_wkflow <- workflow() %>% 
  add_model(elastic_net) %>% 
  add_recipe(pokemon_recipe)

# Set grid with values of `mixture` and `penalty`, and levels
elastic_grid <- grid_regular(penalty(range = c(-5, 5)), mixture(range = c(0, 1)), levels = 10)
```

We have 10 levels for each `mixture` and `penalty` which implies that we would need to estimate 100 combinations of all of them so we can fit the whole grid that we set. Furthermore, we have 5 folds which means that in every single one of them we would need to run the 100 models. Therefore, overall, we need to fit 500 models (100 per each fold but we have 5 folds).


### Exercise 6

Fit the models to your folded data using `tune_grid()`.

Use `autoplot()` on the results. What do you notice? Do larger or smaller values of `penalty` and `mixture` produce better accuracy and ROC AUC?

**Answer**

Following Lab 5:

```{r}
# Fit models to folded data using `tune_grid()`
tune_elastic <- tune_grid(elastic_wkflow,
                          resamples = pokemon_folds, 
                          grid = elastic_grid)

# Use `autoplot()` on the results
autoplot(tune_elastic)
```

The plots show that having a low `mixture` (represented by the Proportion of Lasso Penalty) and `penalty` (represented by the Amount of regularization) yield higher ROC-AUC and accuracy levels when they are smaller. This implies that low values of `mixture` and `penalty`produce higher accuracy levels and improve the ROC-AUC.


### Exercise 7

Use `select_best()` to choose the model that has the optimal `roc_auc`. Then use `finalize_workflow()`, `fit()`, and `augment()` to fit the model to the training set and evaluate its performance on the testing set.

**Answer**

Following Lab 5:

```{r}
# Select best model
best_model <- select_best(tune_elastic, metric = "roc_auc")
best_model

# Fit the selected model
elastic_final <- finalize_workflow(elastic_wkflow, best_model)
elastic_final_fit <- fit(elastic_final, data = pokemon_train)

# Evaluate its performance on the testing set
evaluate <- augment(elastic_final_fit, new_data = pokemon_test) %>% 
  select(type_1, starts_with(".pred"))
```

### Exercise 8

Calculate the overall ROC AUC on the testing set.

Then create plots of the different ROC curves, one per level of the outcome. Also make a heat map of the confusion matrix.

What do you notice? How did your model do? Which Pokemon types is the model best at predicting, and which is it worst at? Do you have any ideas why this might be?

**Answer**

Following Lab 5:

```{r}
# Overall ROC AUC on the testing set
evaluate %>% roc_auc(type_1, .pred_Bug:.pred_Water)

# Plots of the different ROC curves
evaluate %>% roc_curve(type_1, .pred_Bug:.pred_Water) %>% 
  autoplot()

# Heat mapt of the confusion matrix
evaluate %>% conf_mat(truth = type_1, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

Based on the ROC curves, the model does a very good job with Physhic and Normal type Pokemon, but for Grass and Water it does not perform very well. These results are confirmed by the heat maps in which we can see the correctly classifications and those misclassify by the model. For Psychic, the model correctly classified 11 out of 18 pokemon and for Normal 22 out of 30 which are very high levels. On the other hand, for Grass it was only able to properly classifed 2 of them and most of them were actually classify as Water type. Finally, for the Water type only 9 were correctly classified and a huge proportion of them were misclassified.


## For 231 Students

### Exercise 9

In the 2020-2021 season, Stephen Curry, an NBA basketball player, made 337 out of 801 three point shot attempts (42.1%). Use bootstrap resampling on a sequence of 337 1’s (makes) and 464 0’s (misses). For each bootstrap sample, compute and save the sample mean (e.g. bootstrap FG% for the player). Use 1000 bootstrap samples to plot a histogram of those values. Compute the 99% bootstrap confidence interval for Stephen Curry’s “true” end-of-season
FG% using the quantile function in R. Print the endpoints of this interval.

**Answer**

```{r}
# Create values 1 for the first 337 (the ones he made) and 0 for the other 464 (didn't make)
curry <- c(rep(1, 337), rep(0, 464))

bootstrap_results <- NULL # Set it as empty so we can fill it later with the results
set.seed(3435) # Same as usual
for(i in 1:1000){ # Loops work very well with R. With the help of google (several pages, not a single one) and my Stata skills I manage to make a loop in R
  sample_selected <- sample(curry, replace = T) # The sample selected for each iteration
  bootstrap_results[i] <- mean(sample_selected) # Store each iteration result in the empty one created before
}

# Turn it into a tibble and find the CI
data_bootstrap <- tibble(bootstrap_results)

# Histogram
histogram_bootstrap = ggplot(data_bootstrap) + geom_histogram(aes(bootstrap_results), colour = 'navyblue', fill = 'light blue') + labs(title = "Proportion of shot attempts made", y = 'Frequency', x = 'Proportion of attempts')
histogram_bootstrap

# Using quantile function print results
quantile(bootstrap_results, c(0.005, 0.995))
```

The histogram shows that most of the possible outocomes are within 0.40 and 0.45 and it is centered around 0.42. This results is not surprising becuase he made 337 out of the 801 which is exactly 42% of them were made. Therefore, our bootstrap should appropriately reflect that unless major changes happened which is not the case.

The 99% confidence interval is between 0.37 and 0.47 wchich effectively contains the centered valued as expected.
